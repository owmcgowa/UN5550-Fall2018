{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferential Statistics (Chapter 4)\n",
    "\n",
    "We wish to infer parameters of, and draw conclusions about a population using a statistic (number/property describing a characteristic of a sample).  \n",
    "\n",
    "Goal for this module:\n",
    "* Understanding sampling distributions\n",
    "* Method 1: Point estimates\n",
    "* Method 2: Confidence intervals\n",
    "* Method 3: Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets return to the red wine quality data set, and try to better understand samples versus population.  There are two different viewpoints, both valid:\n",
    "* We have only *sampled* some of red wines produced in Northern Portugal.  Hence, the data set we have is a *sample*, which we can use to infer characteristics about red wines produced in Portugal.\n",
    "* We can think of our data set as the population, e.g., the data covers all the varieties of red wines produced at wineries in Portugal in a certain month.  \n",
    "\n",
    "We shall take the latter interpretation for the rest of the lecture. Lets begin by importing our data set as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "# url  =  \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "wine = pd.read_csv(\"data/winequality-red.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learned how to find the mean pH of the wine last day.  Lets call this the population mean, $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = wine[\"pH\"].mean();\n",
    "print(\"mean pH, mu = \" + str(mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps, someone did not believe that red wine was so acidic, and demanded that we re-measure the pH of the wines.  This might be ridiculously time consuming/expensive, and we don't want to take the time to sample all 1588 red wines again.  Instead, what we want to do is take a few random samples of the wine, and convince the appropriate party that the reported mean pH was reasonable.  How do we do that?  How do we quantify our confidence in the reported pH? To do this, we first need to understand how meaningful it is to take the mean of samples.  A key concept is *the sampling distribution of the sample mean*.\n",
    "\n",
    "Suppose that our initial measurements were actually accurate (i.e., if we measured the same wine again, the reported pH will be the same value.  Suppose we were only interested in re-measuring the mean pH of $n=30$ wines.  If we drew all possible samples of size $n=30$, measured the mean of each sample, then the probability distribution of this mean is called the *mean sampling distribution*.  For this example, there are a total of $1588 \\choose 30$ samples. This is a very large number of samples.  We can instead approximate the mean sampling distribution by drawing a large number of samples of size $n=30$, say 1000.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_tests = 1000\n",
    "n = 5\n",
    "means = [0] * N_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the last command generates an array with $N_{test}$ elements, each element is initialized to $0$.  Lets now generate each sample and store the mean of each sample into our new array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_tests):\n",
    "    observations = np.random.choice(wine.index.values,n)\n",
    "    sampled_wines = wine.loc[observations]\n",
    "    means[i] = sampled_wines[\"pH\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now generate a histogram of this plot.  (Note, the underscore suppresses the matplotlib output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 20\n",
    "_ = plt.hist(means,nbins )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central limit theorem tells as that as $n$ is increased, this distribution will approach a normal distribution.  Lets fit a normal distribution to this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "xbar, s = norm.fit(means)\n",
    "print(\"mean = %g, standard deviation of distribution = %g\"%(xbar, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now superimpose the normal distribution plot on top of our histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(means,bins=20,density=True )\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin,xmax,100)\n",
    "p = norm.pdf(x, xbar, s)\n",
    "_ = plt.plot(x, p, 'r', linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our sampling distribution is well approximated by the Gaussian (normal) distribution.  Lets review some properties of the normal distribution:\n",
    "* the distribution is symmetric about it's mean;\n",
    "* there is a single peak, mean = median = mode (most frequently occurring value in series), located at $x = \\mu$;\n",
    "* the distribution has inflection points at $\\mu \\pm \\sigma$, where $\\sigma$ is the standard deviation;\n",
    "* The area under the distribution is 1;\n",
    "* The area under the curve to the left (right) of $\\mu$ is 0.5;\n",
    "* The curve approaches, but never reaches the horizontal axis.\n",
    "\n",
    "We already saw this last day, the normal distribution can be described mathematically by\n",
    "$$ N(\\mu,\\sigma) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left(-\\frac{(x-\\mu)^2}{2 \\sigma^2} \\right).$$\n",
    "Often, we standardize normal data by computing z-scores, so that any Normal curve $N(\\mu,\\sigma^2)$ can be transformed into the standard normal curve $N(0,1)$,\n",
    "$$z = \\frac{x-\\mu}{\\sigma}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Point Estimates\n",
    "We are now ready to describe Method 1: using sample data to give a point estimate (best guess) of the population parameter.  The idea is to take a sample of the population, e.g. $n=30$ wines, and compute the mean of the sample, $\\bar{x}$.  Then, one estimates the population mean, $\\mu$, and standard error, $SE$, using:\n",
    "$$ \\mu = \\bar{x}, \\qquad SE = \\frac{\\sigma}{\\sqrt{n}},$$ where $\\sigma$ is the standard deviation of the population. If the standard deviation of the population is not known, one can use the sample standard deviation if the population distribution is not skewed, and if $n>30$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "observations = np.random.choice(wine.index.values,n)\n",
    "sampled_wines = wine.loc[observations]\n",
    "xbar = sampled_wines[\"pH\"].mean()\n",
    "sigma = wine[\"pH\"].std()\n",
    "se = sigma/np.sqrt(n)\n",
    "print \"Estimate of population mean = %g, standard error = %g\"%(xbar,se)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Confidence Intervals\n",
    "The $100\\cdot(1-\\alpha)\\%$ confidence interval for $\\mu$ is,\n",
    "$$ \\bar{x} \\pm z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}},$$\n",
    "i.e, we use the point estimate for the mean, the $z$-score which determines the confidence interval, and the standard error of the mean.  Lets try and understand this formula by starting with the standard normal (using the $z$-score), and then transforming to the problem at hand.  Suppose we want the confidence level = $C\\% = (1-\\alpha)100 \\%$.  Then\n",
    "\\begin{align}\n",
    "C &= (1-\\alpha)100 \\\\\n",
    "&=P(-z_{\\alpha/2} \\le Z \\le z_{\\alpha/2}) \\\\\n",
    "&= P(-z_{\\alpha/2} \\le \\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}} \\le z_{\\alpha/2})\\\\\n",
    "&= P\\left(-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\le (\\bar{x}-\\mu) \\le z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)\\\\\n",
    "&= P\\left(-\\bar{x}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\le -\\mu \\le -\\bar{x} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)\\\\\n",
    "&= P\\left(\\bar{x}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\ge \\mu \\ge \\bar{x} - z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)\\\\\n",
    "&= P\\left(\\bar{x}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\le \\mu \\le \\bar{x} + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example, if we want a 95% confidence interval, this means $\\alpha=0.05$, which (from a z-table) gives $z_{\\alpha/2} = 1.96$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "z_alphadiv2 = norm.ppf(1-alpha/2)\n",
    "confidence = norm.cdf(z_alphadiv2)-norm.cdf(-z_alphadiv2)\n",
    "ci = [xbar - se*z_alphadiv2, xbar + se*z_alphadiv2 ]\n",
    "print \"We are\", 100*confidence, \"% confident that the interval = \",  ci,  \"contains the mean.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: what does this 95% confident mean? We cannot say that our specific sample has a 95% chance of containing the true parameter.    Rather, a correct interpretation is, if we were to take 100 samples and compute 100 confidence intervals, 95% of the confidence intervals are likely to contain the true mean of the population.  Lets explore and see:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = 100\n",
    "n = 30\n",
    "means = np.array([0.0] * N_test)   # initialize list for means\n",
    "sigma = np.array([0.0] * N_test)   # initialize list for standard deviation\n",
    "ci = np.array([[0.0,0.0]] * N_test)  # initialize list for confidence intervals\n",
    "mu = wine[\"pH\"].mean()  # true mean\n",
    "for i in range(N_test):\n",
    "    observations = np.random.choice(wine.index.values,n)\n",
    "    sampled_wines = wine.loc[observations]\n",
    "    means[i] = sampled_wines[\"pH\"].mean()\n",
    "    sigma[i] = sampled_wines[\"pH\"].std()\n",
    "    ci[i] = means[i] + np.array([-sigma[i] * z_alphadiv2/np.sqrt(n), sigma[i]*z_alphadiv2/np.sqrt(n)])\n",
    "\n",
    "out1 = ci[:,0] > mu # flag CI that do not contain the \"true\" mean\n",
    "out2 = ci[:,1] < mu # flag CI that do not contain the \"true\" mean\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "ind = np.arange(1, N_test+1)\n",
    "ax.axhline(y = mu, \n",
    "           xmin = 0, \n",
    "           xmax = N_test+1, \n",
    "           color = [0, 0, 0])\n",
    "\n",
    "ci = np.transpose(ci)\n",
    "ax.plot([ind,ind], \n",
    "        ci, \n",
    "        color = '0.75', \n",
    "        marker = '_', \n",
    "        ms = 0, \n",
    "        linewidth = 3)\n",
    "ax.plot([ind[out1],ind[out1]], \n",
    "        ci[:, out1], \n",
    "        color = [1, 0, 0, 0.8], \n",
    "        marker = '_', \n",
    "        ms = 0, \n",
    "        linewidth = 3)\n",
    "ax.plot([ind[out2],ind[out2]], \n",
    "        ci[:, out2], \n",
    "        color = [1, 0, 0, 0.8], \n",
    "        marker = '_',\n",
    "        ms = 0, \n",
    "        linewidth = 3)\n",
    "ax.plot(ind, \n",
    "        means, \n",
    "        color = [0, .8, .2, .8], \n",
    "        marker = '.',\n",
    "        ms = 10, \n",
    "        linestyle = '')\n",
    "ax.set_ylabel(\"Confidence interval for the samples' mean estimate\",\n",
    "              fontsize = 12)\n",
    "ax.set_xlabel('Samples (with %d observations). '  %n, \n",
    "              fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the population standard deviation, $\\sigma$, is unknown, then we need to estimate the population standard deviation.  Compare:\n",
    "\\begin{align}\n",
    "  Z = \\frac{\\bar{x}-\\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)\n",
    "\\end{align}\n",
    "and\n",
    "\\begin{align}\n",
    "T = \\frac{\\bar{x}-\\mu}{s/\\sqrt{n}} \\sim t(df = n-1)\n",
    "\\end{align}\n",
    "Lets compare the $T$-distribution to the normal distribution.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmin = -10\n",
    "xmax = 10\n",
    "x = np.linspace(xmin,xmax,100)\n",
    "p = norm.pdf(x, 0, 1)\n",
    "_ = plt.plot(x, p, 'r', linewidth = 2,label=\"z-curve\")\n",
    "_ = plt.legend()\n",
    "\n",
    "from scipy.stats import t\n",
    "dof = 29;\n",
    "q = t.pdf(x,dof)\n",
    "_ = plt.plot(x, q, 'b', linewidth = 2,label=\"T, dof=%d\"%(dof))\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the normal distribution, the T-distribution is symmetric about the mean.  However, it is shorter and wider than the Z-curve.  It has an extra parameter (Degree of Freedom). In our case, the degree of freedom is one less than the number of observations.  If the population standard deviation is not known (often the case), one should use the T-distribution rather than the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:  An engineer working for Ford is interested in the population of all vehicles that have an engine size of 3.0L or larger, and is particular interested in $\\mu$, the highway mileage (mpg).  Assume the population is normally distributed.  The sample mean among a random sample of 14 vehicles is 18.3 mpg, and the sample standard deviation is 5.1 mpg (note: $\\sigma$ is unknown).  What is the 95% CI for $\\mu$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "xbar = 18.3\n",
    "n = 14\n",
    "se = 5.1/np.sqrt(n) # if 5.1 was the population standard deviation, \n",
    "z_alphadiv2 = norm.ppf(1-alpha/2)\n",
    "confidence = norm.cdf(z_alphadiv2)-norm.cdf(-z_alphadiv2)\n",
    "ci = [xbar - se*z_alphadiv2, xbar + se*z_alphadiv2 ]\n",
    "print \"We are\", 100*confidence, \"% confident that the interval = \",  ci,  \"contains the mean.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but, we actually have s= 5.1, the sample standard deviation, so we need to the t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "xbar = 18.3\n",
    "n = 14\n",
    "dof = n-1\n",
    "se = 5.1/np.sqrt(n) #  5.1 was the sample standard deviation, \n",
    "t_alphadiv2 = t.ppf(1-alpha/2,dof)\n",
    "confidence = t.cdf(t_alphadiv2,dof)-t.cdf(-t_alphadiv2,dof)\n",
    "ci = [xbar - se*t_alphadiv2, xbar + se*t_alphadiv2 ]\n",
    "print \"We are\", 100*confidence, \"% confident that the interval = \",  ci,  \"contains the mean.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "Hypothesis: Statement to be tested.  Often, this is referred to as the null hypothesis, $H_0$.  The alternative hypothesis $H_a$ is, as the name suggests, the alternative to null hypothesis (if $H_0$ is not true, what do I suspect might be true instead?) \n",
    "\n",
    "There are two competing camps for hypothesis testing:\n",
    "* Bayesian inference: a probability is assigned/computed for a hypothesis\n",
    "* Frequentist approach: depends on likelihood of observed/unobserved data.\n",
    "\n",
    "### Comment:\n",
    "We will cover (as per the textbook) the frequentist approach, using frequentist measures like $p$-values and confidence intervals.  This has been the dominant approach to conducting hypothesis testing over the last two decades.  I do want to take a few minutes to talk about the Bayesian approach, since more recently, the Bayesian inference (MA 5770) has been garnering enthusiasm in fields like machine learning.  Bayesian inference uses the idea of conditional probability (e.g. P(A|B): probability that event A happens given event B) to determine which hypothesis is most probable.  One has to specify a prior distribution  about the probability distribution that represents the statistic one cares about.  To use Bayesian inference, one needs a full understanding of the statistical model.  Lets return to the frequentist approach for hypothesis testing.\n",
    "\n",
    "### Five-Step Procedure\n",
    "1. Formulate the appropriate hypothesis\n",
    "2. Decide on an appropriate test statistic\n",
    "3. Specify the critical region for the test statistics\n",
    "4. Conduct the experiment and find the specific value for the test statistic\n",
    "5. Reach an appropriate conclusion and state them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Hypothesis\n",
    "A common example is drawn from the judicial system: innocent until proven guilty.  Here,\n",
    "* $H_0$: defendant is innocent\n",
    "* $H_a$: defendant is guilty\n",
    "\n",
    "    \n",
    "<table border=1px>\n",
    "    <tr>\n",
    "        <th>Defendant State</th>\n",
    "        <th>Convict (reject $H_0$) </th>\n",
    "        <th>Acquit (do not reject $H_0$)</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Innocent ($H_0$ is true)</td>\n",
    "        <td>Type I error</td>\n",
    "        <td> OK</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Guilty ($H_0$ is false)</td>\n",
    "        <td>OK</td>\n",
    "        <td>Type II error</td>\n",
    "    </tr>\n",
    "    </table>\n",
    "\n",
    "* Type I error: mistake of rejecting the null hypothesis when it was in fact true.  The probability of committing a type I error is often denoted by $\\alpha$ (note: overloaded use of variable $\\alpha$).\n",
    "* Type II error: mistake of failing to reject the null hypothesis when it is false.  The probability of committing a type II error is often denoted by $\\beta$.\n",
    "\n",
    "There are several common types of hypothesis:\n",
    "1. Equal versus not equal hypothesis (a.k.a. two-tailed test)\n",
    "    * $H_0$: parameter = some value (e.g. $H_0: \\mu = 17$)\n",
    "    * $H_a$: parameter $\\neq$ some value (e.g. $H_a: \\mu \\neq 17$)\n",
    "2. Equal versus greater than hypothesis (a.k.a. right-tailed test)\n",
    "    * $H_0$: parameter = some value (e.g. $H_0: \\mu = 17$)\n",
    "    * $H_a$: parameter $>$ some value (e.g. $H_a: \\mu > 17$)    \n",
    "3. Equal versus less than hypothesis (a.k.a. left-tailed test)\n",
    "    * $H_0$: parameter = some value (e.g. $H_0: \\mu = 17$)\n",
    "    * $H_a$: parameter $<$ some value (e.g. $H_a: \\mu < 17$)   \n",
    "    \n",
    "## Test Statistic\n",
    "Let $\\mu_0$ be the nominal value for $\\mu$, i.e., for the three types of hypothesis above:\n",
    "1. $H_0: \\mu = \\mu_0$, $H_a: \\mu \\neq \\mu_0$\n",
    "2. $H_0: \\mu = \\mu_0$, $H_a: \\mu > \\mu_0$\n",
    "3. $H_0: \\mu = \\mu_0$, $H_a: \\mu < \\mu_0$\n",
    "If $\\sigma$ (population standard deviation is known, use\n",
    "$$ Z = \\frac{\\bar{x}-\\mu_0}{\\sigma/\\sqrt{n}} \\sim N(0,1). $$\n",
    "Otherwise, if $\\sigma$ is not known, use\n",
    "$$ T = \\frac{\\bar{x}-\\mu_0}{s/\\sqrt{n}} \\sim t(df=n-1). $$\n",
    "\n",
    "## Critical Regions\n",
    "two-tail test ($H_0: \\mu = \\mu_0$, $H_a: \\mu \\neq \\mu_0$):\n",
    "<img src=\"figures/two_tail.png\">\n",
    "\n",
    "left-tail test ($H_0: \\mu = \\mu_0$, $H_a: \\mu < \\mu_0$):\n",
    "<img src=\"figures/left_tail.png\">\n",
    "\n",
    "right-tail test ($H_0: \\mu = \\mu_0$, $H_a: \\mu > \\mu_0$):\n",
    "<img src=\"figures/right_tail.png\">\n",
    "\n",
    "## Conduct the experiment\n",
    "Find the specific value of the test statistic.  Note:\n",
    "* One should always complete the first three steps **before** any data is colected\n",
    "* A well-planned experiment should have clear criteria for making decisions before the data collection, in order to ensure objectivity\n",
    "\n",
    "## Conclusions\n",
    "If the test statistic falls inside the critical region, we reject $H_0$\n",
    "* We reject $H_0$ if we have **significant** evidence at level $\\alpha$ that $H_0$ is false\n",
    "* We do not reject $H_0$ if data is **NOT significant** at level $\\alpha$.\n",
    "\n",
    "Lets quantify this.  One often computes a $p$-value, the probability of observing the computed statistic if the null hypothesis is true.  The $p$-value measures, in some sense, how far into the tail we are, based on the computed statistic, i.e., how significant the observation is.  The closer the $p$-value is to zero, the more evidence we have against $H_0$.  We reject $H_0$ if $p$-value $< \\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: lets go back to the pH of our red wines.  Lets recompute the population mean and standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = wine[\"pH\"].mean()\n",
    "sigma = wine[\"pH\"].std()\n",
    "print(\"mean = %g, sigma = %g\"%(mu,sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now, we want to take a sample of 30 wines.  Suppose that our hypothesis is that the mean is 3.3.  The alternative hypothesis, is that the mean is different from 3.31 (i.e., a two-tail test).  Lets sample the population and compute the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "observations = np.random.choice(wine.index.values,n)\n",
    "sampled_wines = wine.loc[observations]\n",
    "xbar = sampled_wines[\"pH\"].mean()\n",
    "\n",
    "z = (xbar - 3.1) / (sigma/np.sqrt(n))\n",
    "\n",
    "alpha = 0.05\n",
    "pvalue = 2*(1-norm.cdf(np.abs(z))) # note: the factor of 2 is here because of the two-tailed test\n",
    "\n",
    "print \"The p-value is %g\"%(pvalue)\n",
    "\n",
    "\n",
    "if (pvalue < alpha):\n",
    "    print \"We reject the null hypothesis\"\n",
    "else:\n",
    "    print \"we have no evidence to reject the null hypothesis\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are convenient relationships between confidence intervals and hypothesis testing. \n",
    "* Sometimes, we compute a CI for $\\mu$ after rejecting $H_0$ to report the location of plausible values for $\\mu$.\n",
    "* A two-sided hypothesis test with a significance level of $\\alpha$ is\n",
    "equivalent to constructing a $(1- \\alpha)100\\%$ confidence interval for $\\mu$.\n",
    "* We can check whether the CI contains $\\mu_0$:\n",
    "    * If the interval does contain $\\mu_0$, then we fail to reject $H_0$.\n",
    "    * If the interval does not contain $\\mu_0$, then we reject $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power of a test\n",
    "The power of a hypothesis test is the probability that we reject the\n",
    "null hypothesis when the alternative hypothesis is true.\n",
    "\\begin{align}\n",
    "P(\\text{reject } H_0 \\,| \\, H_a \\text{ is true}).\n",
    "\\end{align}\n",
    "For example, suppose we want to test $H_0: \\mu = \\mu_0$, and $H_a: \\mu> \\mu_0$.  The statistic is computed using:\n",
    "$$ z = \\frac{\\bar{x}-\\mu_0}{ \\frac{\\sigma}{\\sqrt{n}}}.$$\n",
    "The critical region is $z>z_{\\alpha}$, the power is $P(z>z_\\alpha \\,| \\,\\mu = \\mu_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
